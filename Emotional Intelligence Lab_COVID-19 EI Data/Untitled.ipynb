{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_forms.word_forms import get_word_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Doc2Vec' has no attribute 'TaggedDocument'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d0a48097ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \"they chat amagingly well\"]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2d0a48097ffa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \"they chat amagingly well\"]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Doc2Vec' has no attribute 'TaggedDocument'"
     ]
    }
   ],
   "source": [
    "Doc2Vec.\n",
    "data = [\"I love machine learning. Its awesome.\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building chatbots\",\n",
    "        \"they chat amagingly well\"]\n",
    "\n",
    "tagged_data = [Doc2Vec.TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x1a3c6d1828>\n"
     ]
    }
   ],
   "source": [
    "#Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FT_gensim(size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('overnight', 0.9999913573265076),\n",
      " ('night.', 0.9999882578849792),\n",
      " ('hearing', 0.9999879598617554),\n",
      " ('overnight.', 0.9999878406524658),\n",
      " ('enter', 0.9999871253967285),\n",
      " ('according', 0.999987006187439),\n",
      " ('led', 0.9999869465827942),\n",
      " ('fighting', 0.9999869465827942),\n",
      " ('planning', 0.9999868869781494),\n",
      " ('right', 0.9999867677688599)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"night\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import os\n",
    "# this turns off some pesky warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=Warning)\n",
    "\n",
    "# direct plots to appear within the cell, and set their style\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gdl\n",
    "from gensim.models import KeyedVectors\n",
    "glove = gdl.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harvard', 0.9161344766616821),\n",
       " ('princeton', 0.867539644241333),\n",
       " ('university', 0.8113802075386047),\n",
       " ('cornell', 0.801445484161377),\n",
       " ('stanford', 0.7877545356750488),\n",
       " ('graduate', 0.7834290862083435),\n",
       " ('professor', 0.7497232556343079),\n",
       " ('graduated', 0.7449983358383179),\n",
       " ('college', 0.7335599660873413),\n",
       " ('dartmouth', 0.7325829267501831)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar('yale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration__in_seconds_</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>OpenEmotions_1</th>\n",
       "      <th>OpenEmotions_3</th>\n",
       "      <th>OpenEmotions_4</th>\n",
       "      <th>ClosedEmotions_1</th>\n",
       "      <th>ClosedEmotions_2</th>\n",
       "      <th>ClosedEmotions_3</th>\n",
       "      <th>ClosedEmotions_4</th>\n",
       "      <th>ClosedEmotions_5</th>\n",
       "      <th>ClosedEmotions_6</th>\n",
       "      <th>StressCauses_1</th>\n",
       "      <th>StressCauses_12</th>\n",
       "      <th>StressCauses_13</th>\n",
       "      <th>JoyCauses_1</th>\n",
       "      <th>JoyCauses_12</th>\n",
       "      <th>JoyCauses_13</th>\n",
       "      <th>Strats_EffectiveSelf_1</th>\n",
       "      <th>Strats_EffectiveSelf_2</th>\n",
       "      <th>Strats_EffectiveSelf_3</th>\n",
       "      <th>Strats_EffectiveOthe_1</th>\n",
       "      <th>Strats_EffectiveOthe_2</th>\n",
       "      <th>Strats_EffectiveOthe_3</th>\n",
       "      <th>ER_1</th>\n",
       "      <th>ER_2</th>\n",
       "      <th>WellBeingSupport_16</th>\n",
       "      <th>WellBeingSupport_17</th>\n",
       "      <th>WellBeingSupport_18</th>\n",
       "      <th>CASELWebinars_16</th>\n",
       "      <th>CASELWebinars_17</th>\n",
       "      <th>CASELWebinars_18</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race_1</th>\n",
       "      <th>Race_2</th>\n",
       "      <th>Race_3</th>\n",
       "      <th>Race_4</th>\n",
       "      <th>Race_5</th>\n",
       "      <th>Race_6</th>\n",
       "      <th>Race_7</th>\n",
       "      <th>Race_8</th>\n",
       "      <th>Race_8_TEXT</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gender_3_TEXT</th>\n",
       "      <th>Educator</th>\n",
       "      <th>Role_11</th>\n",
       "      <th>Role_12</th>\n",
       "      <th>Role_1</th>\n",
       "      <th>Role_2</th>\n",
       "      <th>Role_3</th>\n",
       "      <th>Role_4</th>\n",
       "      <th>Role_5</th>\n",
       "      <th>Role_6</th>\n",
       "      <th>Role_7</th>\n",
       "      <th>Role_8</th>\n",
       "      <th>Role_10</th>\n",
       "      <th>Role_10_TEXT</th>\n",
       "      <th>Grade_1</th>\n",
       "      <th>Grade_2</th>\n",
       "      <th>Grade_3</th>\n",
       "      <th>Grade_4</th>\n",
       "      <th>StudentSES_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-24 16:47:03</td>\n",
       "      <td>2020-03-24 16:52:06</td>\n",
       "      <td>100.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-24 16:52:06</td>\n",
       "      <td>R_Q64hfjjdCiGnM09</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Fearful</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>uncertainty</td>\n",
       "      <td>News</td>\n",
       "      <td>updates</td>\n",
       "      <td>kids</td>\n",
       "      <td>work</td>\n",
       "      <td>family</td>\n",
       "      <td>stop soical media</td>\n",
       "      <td>running</td>\n",
       "      <td>journaling</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-24 16:48:25</td>\n",
       "      <td>2020-03-24 16:52:45</td>\n",
       "      <td>100.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-24 16:52:45</td>\n",
       "      <td>R_Anw03Hj4s7jxnfH</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>fear</td>\n",
       "      <td>hope</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>worry about others</td>\n",
       "      <td>worry about self</td>\n",
       "      <td>loss of normal routine</td>\n",
       "      <td>connecting with others</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>yoga</td>\n",
       "      <td>connecting with others</td>\n",
       "      <td></td>\n",
       "      <td>listen to them</td>\n",
       "      <td>provide facts</td>\n",
       "      <td>provide resources</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Less cognitive demands</td>\n",
       "      <td>Show grace and understanding</td>\n",
       "      <td>Listen to what people need</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-24 16:51:16</td>\n",
       "      <td>2020-03-24 16:52:49</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-24 16:52:49</td>\n",
       "      <td>R_32UYohfSNVrkECi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-24 16:47:38</td>\n",
       "      <td>2020-03-24 16:53:13</td>\n",
       "      <td>100.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-24 16:53:13</td>\n",
       "      <td>R_24PeWDZ57ldPxMy</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Anger</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Uncertainty</td>\n",
       "      <td>Change</td>\n",
       "      <td>Finances</td>\n",
       "      <td>Family</td>\n",
       "      <td>Connectedness</td>\n",
       "      <td>Quiet</td>\n",
       "      <td>Breathing</td>\n",
       "      <td>Meditation</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>Calm leadership</td>\n",
       "      <td>Meditation</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Reassurance</td>\n",
       "      <td>Non-education related activities that increase...</td>\n",
       "      <td>Ways of increasing normalcy, routine, and conn...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-24 16:46:45</td>\n",
       "      <td>2020-03-24 16:53:26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-03-24 16:53:26</td>\n",
       "      <td>R_wMCGldjiVHje0o1</td>\n",
       "      <td>Panic</td>\n",
       "      <td>Terror</td>\n",
       "      <td>Depression</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fear for my health</td>\n",
       "      <td>Fear for my family’s health</td>\n",
       "      <td>Social isolation</td>\n",
       "      <td>My son’s smile</td>\n",
       "      <td>My son’s laughter</td>\n",
       "      <td>Old VMs from a friend</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>EFT</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Outside time</td>\n",
       "      <td>Validating feelings</td>\n",
       "      <td>Hugging</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Acceptance of all feelings</td>\n",
       "      <td>Tools to use in the moment</td>\n",
       "      <td>Space</td>\n",
       "      <td>Access to physical touch</td>\n",
       "      <td>Self reg strategies</td>\n",
       "      <td>EFT</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private SLP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StartDate             EndDate  Progress  Duration__in_seconds_  \\\n",
       "0 2020-03-24 16:47:03 2020-03-24 16:52:06     100.0                  302.0   \n",
       "1 2020-03-24 16:48:25 2020-03-24 16:52:45     100.0                  259.0   \n",
       "2 2020-03-24 16:51:16 2020-03-24 16:52:49     100.0                   92.0   \n",
       "3 2020-03-24 16:47:38 2020-03-24 16:53:13     100.0                  334.0   \n",
       "4 2020-03-24 16:46:45 2020-03-24 16:53:26     100.0                  400.0   \n",
       "\n",
       "   Finished        RecordedDate         ResponseId OpenEmotions_1  \\\n",
       "0       1.0 2020-03-24 16:52:06  R_Q64hfjjdCiGnM09        Anxious   \n",
       "1       1.0 2020-03-24 16:52:45  R_Anw03Hj4s7jxnfH        anxiety   \n",
       "2       1.0 2020-03-24 16:52:49  R_32UYohfSNVrkECi                  \n",
       "3       1.0 2020-03-24 16:53:13  R_24PeWDZ57ldPxMy           Fear   \n",
       "4       1.0 2020-03-24 16:53:26  R_wMCGldjiVHje0o1          Panic   \n",
       "\n",
       "  OpenEmotions_3 OpenEmotions_4  ClosedEmotions_1  ClosedEmotions_2  \\\n",
       "0            Sad        Fearful               6.0               6.0   \n",
       "1           fear           hope               5.0               6.0   \n",
       "2                                             NaN               NaN   \n",
       "3        Sadness          Anger               5.0               5.0   \n",
       "4         Terror     Depression               3.0               5.0   \n",
       "\n",
       "   ClosedEmotions_3  ClosedEmotions_4  ClosedEmotions_5  ClosedEmotions_6  \\\n",
       "0               3.0               5.0               5.0               3.0   \n",
       "1               3.0               4.0               3.0               4.0   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "3               4.0               5.0               4.0               3.0   \n",
       "4               4.0               4.0               4.0               5.0   \n",
       "\n",
       "       StressCauses_1              StressCauses_12         StressCauses_13  \\\n",
       "0         uncertainty                         News                 updates   \n",
       "1  worry about others             worry about self  loss of normal routine   \n",
       "2                                                                            \n",
       "3         Uncertainty                       Change                Finances   \n",
       "4  Fear for my health  Fear for my family’s health        Social isolation   \n",
       "\n",
       "              JoyCauses_1       JoyCauses_12           JoyCauses_13  \\\n",
       "0                    kids               work                 family   \n",
       "1  connecting with others                                             \n",
       "2                                                                     \n",
       "3                  Family      Connectedness                  Quiet   \n",
       "4          My son’s smile  My son’s laughter  Old VMs from a friend   \n",
       "\n",
       "  Strats_EffectiveSelf_1  Strats_EffectiveSelf_2 Strats_EffectiveSelf_3  \\\n",
       "0      stop soical media                 running             journaling   \n",
       "1                   yoga  connecting with others                          \n",
       "2                                                                         \n",
       "3              Breathing              Meditation               Exercise   \n",
       "4                   Yoga                     EFT                 Nature   \n",
       "\n",
       "  Strats_EffectiveOthe_1 Strats_EffectiveOthe_2 Strats_EffectiveOthe_3  ER_1  \\\n",
       "0                                                                        NaN   \n",
       "1         listen to them          provide facts      provide resources   3.0   \n",
       "2                                                                        NaN   \n",
       "3        Calm leadership             Meditation               Optimism   5.0   \n",
       "4           Outside time    Validating feelings                Hugging   5.0   \n",
       "\n",
       "   ER_2         WellBeingSupport_16  \\\n",
       "0   NaN                               \n",
       "1   4.0      Less cognitive demands   \n",
       "2   NaN                               \n",
       "3   6.0                 Reassurance   \n",
       "4   5.0  Acceptance of all feelings   \n",
       "\n",
       "                                 WellBeingSupport_17  \\\n",
       "0                                                      \n",
       "1                       Show grace and understanding   \n",
       "2                                                      \n",
       "3  Non-education related activities that increase...   \n",
       "4                         Tools to use in the moment   \n",
       "\n",
       "                                 WellBeingSupport_18  \\\n",
       "0                                                      \n",
       "1                         Listen to what people need   \n",
       "2                                                      \n",
       "3  Ways of increasing normalcy, routine, and conn...   \n",
       "4                                              Space   \n",
       "\n",
       "           CASELWebinars_16     CASELWebinars_17 CASELWebinars_18 Age  Race_1  \\\n",
       "0                                                                         NaN   \n",
       "1                                                                  39     NaN   \n",
       "2                                                                         NaN   \n",
       "3                                                                  36     NaN   \n",
       "4  Access to physical touch  Self reg strategies              EFT         NaN   \n",
       "\n",
       "   Race_2  Race_3  Race_4  Race_5  Race_6  Race_7  Race_8 Race_8_TEXT  Gender  \\\n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN                 NaN   \n",
       "1     NaN     NaN     NaN     NaN     NaN     1.0     NaN                 2.0   \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN                 NaN   \n",
       "3     NaN     NaN     NaN     NaN     NaN     1.0     NaN                 2.0   \n",
       "4     NaN     NaN     NaN     NaN     NaN     1.0     NaN                 2.0   \n",
       "\n",
       "  Gender_3_TEXT  Educator  Role_11  Role_12  Role_1  Role_2  Role_3  Role_4  \\\n",
       "0                     NaN      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "1                     2.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "2                     NaN      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "3                     1.0      1.0      NaN     NaN     NaN     NaN     NaN   \n",
       "4                     1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   Role_5  Role_6  Role_7  Role_8  Role_10 Role_10_TEXT  Grade_1  Grade_2  \\\n",
       "0     NaN     NaN     NaN     NaN      NaN                   NaN      NaN   \n",
       "1     NaN     NaN     NaN     NaN      NaN                   NaN      NaN   \n",
       "2     NaN     NaN     NaN     NaN      NaN                   NaN      NaN   \n",
       "3     NaN     NaN     NaN     NaN      NaN                   NaN      NaN   \n",
       "4     NaN     NaN     NaN     NaN      1.0  Private SLP      1.0      1.0   \n",
       "\n",
       "   Grade_3  Grade_4  StudentSES_1  \n",
       "0      NaN      NaN           NaN  \n",
       "1      NaN      NaN           NaN  \n",
       "2      NaN      NaN           NaN  \n",
       "3      NaN      1.0           5.0  \n",
       "4      NaN      1.0           8.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "pd.set_option('display.max_columns', None)\n",
    "df, meta = pyreadstat.read_sav('Emotional Well-Being - CASEL COVID-19 Webinar_Anon.sav')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_feelings_current_climate = []\n",
    "##\n",
    "##Append variables\n",
    "aux = np.append(most_feelings_current_climate, df['StressCauses_1'])\n",
    "aux1 = np.append(aux, df['StressCauses_12'])\n",
    "aux2strat = np.append(aux1, df['StressCauses_13'])\n",
    "\n",
    "##Create series and lovercase all characters\n",
    "##/\n",
    "all_strats = pd.Series(pd.Series([x.lower() for x in aux2strat]))\n",
    "all_strategies  = pd.Series([i for i in all_strats if i])\n",
    "\n",
    "strategies = list(all_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  745M    0   492    0     0   1037      0   8d 17h --:--:--   8d 17h  1037x ./\n",
      "x ./tfhub_module.pb\n",
      "x ./variables/\n",
      " 99  745M   99  744M    0     0  7361k      0  0:01:43  0:01:43 --:--:-- 7351k0:00:23 8735k\n",
      "x ./variables/variables.index\n",
      "x ./assets/\n",
      "100  745M  100  745M    0     0  7366k      0  0:01:43  0:01:43 --:--:-- 7348k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download the model to local so it can be used again and again\n",
    "!mkdir -p ../nicholashelms/Downloads/module_useT\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "!curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC ../nicholashelms/Downloads/module_useT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding[0.04498474299907684, -0.05743392929434776, 0.0022114645689725876,...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding[0.05568017438054085, -0.00960790365934372, 0.006246295291930437,...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding[0.03874938562512398, 0.0765201598405838, -0.0007945871911942959,...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed = hub.Module(\"../nicholashelms/Downloads/module_useT\")\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings = session.run(embed(messages))\n",
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "        print(\"Message: {}\".format(messages[i]))\n",
    "        print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "        message_embedding_snippet = \", \".join((str(x) for x in        message_embedding[:3]))\n",
    "        print(\"Embedding[{},...]\\n\".\n",
    "                   format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Function so that one session can be called multiple times. \n",
    "#Useful while multiple calls need to be done for embedding. \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "embed_fn = embed_useT('../nicholashelms/Downloads/module_useT')\n",
    "messages = strategies\n",
    "strategy_embeddings = embed_fn(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.34479713, 0.22364551, 0.37492228, 0.32398397,\n",
       "        0.48963732, 0.5463667 ],\n",
       "       [0.34479713, 1.0000002 , 0.24881463, 0.26576504, 0.28000006,\n",
       "        0.35177106, 0.48819306],\n",
       "       [0.22364551, 0.24881463, 0.9999999 , 0.20451716, 0.18566976,\n",
       "        0.41487712, 0.43075797],\n",
       "       [0.37492228, 0.26576504, 0.20451716, 0.99999976, 0.7298063 ,\n",
       "        0.6651236 , 0.45158228],\n",
       "       [0.32398397, 0.28000006, 0.18566976, 0.7298063 , 1.0000001 ,\n",
       "        0.5704439 , 0.3193873 ],\n",
       "       [0.48963732, 0.35177106, 0.41487712, 0.6651236 , 0.5704439 ,\n",
       "        1.0000001 , 0.742738  ],\n",
       "       [0.5463667 , 0.48819306, 0.43075797, 0.45158228, 0.3193873 ,\n",
       "        0.742738  , 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_matrix = embed_fn(messages)\n",
    "import numpy as np\n",
    "np.inner(encoding_matrix, encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
