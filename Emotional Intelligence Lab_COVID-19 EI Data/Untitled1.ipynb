{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to help with analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk, re, tweepy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from textblob import TextBlob\n",
    "from sklearn.manifold import TSNE\n",
    "from textblob import Word\n",
    "from spellchecker import SpellChecker\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, meta = pyreadstat.read_sav('Emotional Well-Being - CASEL COVID-19 Webinar_Anon.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_feelings_current_climate = []\n",
    "aux = np.append(most_feelings_current_climate, df['OpenEmotions_1'])\n",
    "aux1 = np.append(aux, df['OpenEmotions_3'])\n",
    "aux2strat = np.append(aux1, df['OpenEmotions_4'])\n",
    "\n",
    "all_strats = pd.Series(pd.Series([x.lower() for x in aux2strat]))\n",
    "ordered_counts_strat = all_strats.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxious', 'anxiety', '', ..., 'frustration', 'Anxious', 'Anxiety'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux2strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x.lower() for x in aux2strat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'jou',\n",
       " 'disapointment',\n",
       " 'coraje',\n",
       " 'sureal',\n",
       " ' disconnected',\n",
       " 'overhelmed',\n",
       " 'optomism',\n",
       " 'disregulated',\n",
       " 'desperated',\n",
       " 'overwehlmed',\n",
       " 'disapppointment',\n",
       " 'insercurity',\n",
       " 'vigilence',\n",
       " 'overstimulated',\n",
       " 'fearfull',\n",
       " 'meh',\n",
       " 'peacefull',\n",
       " 'lonyless',\n",
       " 'axiety',\n",
       " 'esperanza',\n",
       " ' tiredness',\n",
       " 'intruiged',\n",
       " 'fearworry',\n",
       " 'sadnesz',\n",
       " 'pensiveness',\n",
       " 'compasion',\n",
       " 'optomistic',\n",
       " 'flexibilty',\n",
       " 'nonproductive',\n",
       " 'gratitud',\n",
       " 'unuseful',\n",
       " 'overwhelemed',\n",
       " 'overextended',\n",
       " 'wortied',\n",
       " 'oberwhelmed',\n",
       " 'cinfused',\n",
       " 'uncertianty',\n",
       " ' fear',\n",
       " 'greif',\n",
       " 'usure',\n",
       " 'uncertantiy',\n",
       " 'anticiaption',\n",
       " 'hopefullness',\n",
       " 'gratitutde',\n",
       " 'wowed',\n",
       " 'notconsentingtothissurvey',\n",
       " 'supporitive',\n",
       " 'releif',\n",
       " 'unaccomplished',\n",
       " 'fired_up',\n",
       " 'antsy',\n",
       " 'energetized',\n",
       " ' anxious',\n",
       " 'serviceful',\n",
       " 'feer',\n",
       " 'greatful',\n",
       " 'alientated',\n",
       " 'underappreciated',\n",
       " 'stressfull',\n",
       " 'not-grounded',\n",
       " 'miedo',\n",
       " 'overwelm',\n",
       " 'stress/uncertainty',\n",
       " 'curiousness',\n",
       " 'confussed',\n",
       " 'overwelhmed',\n",
       " 'well-rested',\n",
       " 'mindfulness',\n",
       " 'emotiom',\n",
       " 'enxiety',\n",
       " 'confusion.',\n",
       " 'uncertainity',\n",
       " 'ansiedad',\n",
       " 'nervouse',\n",
       " 'unknowingness',\n",
       " 'curiousity',\n",
       " 'overwhelmingness',\n",
       " 'suppory',\n",
       " 'fewr',\n",
       " 'lonliness',\n",
       " 'emotional/teary',\n",
       " 'gratitute',\n",
       " 'scatter-brained',\n",
       " 'unmmotivated',\n",
       " 'uncertaint',\n",
       " 'helplessnes',\n",
       " 'preocuppied',\n",
       " 'mixed-feelings',\n",
       " 'acceptence',\n",
       " 'disipointment',\n",
       " 'afriad',\n",
       " 'distructive',\n",
       " 'ovewhelmed',\n",
       " 'optimisim',\n",
       " 'disagrement',\n",
       " 'fraustrated',\n",
       " 'desesperate',\n",
       " 'bordom',\n",
       " 'uninspiried',\n",
       " 'confussion',\n",
       " 'anxiety/dread',\n",
       " 'undecisive',\n",
       " 'enegized',\n",
       " 'refocused',\n",
       " ' anguish',\n",
       " 'bummed',\n",
       " 'underprepared',\n",
       " 'sleepliness',\n",
       " 'frustation',\n",
       " 'frustraion',\n",
       " 'aprehension',\n",
       " 'stagnet',\n",
       " ' confusion',\n",
       " 'happy/relief',\n",
       " 'thoughfulness',\n",
       " 'unkown',\n",
       " 'appathy',\n",
       " 'gloominess',\n",
       " 'uncentered',\n",
       " 'demotivated',\n",
       " 'introsepective',\n",
       " 'gradititude',\n",
       " 'prayerfulness',\n",
       " 'anxiousnesss',\n",
       " 'destablized',\n",
       " 'nonroutine',\n",
       " 'unbelieveable',\n",
       " 'vigor',\n",
       " 'micromanaged',\n",
       " 'anxiousness',\n",
       " 'dispair',\n",
       " ' helplesss',\n",
       " 'frustrarted',\n",
       " 'hopefull',\n",
       " 'skeptism',\n",
       " 'scatterdness',\n",
       " 'anticontagion',\n",
       " 'paranoias',\n",
       " 'rumination',\n",
       " 'overehelmed',\n",
       " 'overwhlemed',\n",
       " 'overthinking',\n",
       " 'cofusion',\n",
       " 'over-worked',\n",
       " 'releived',\n",
       " 'helplesss',\n",
       " 'disappointmemt',\n",
       " 'overwhelmned',\n",
       " 'lonlieness',\n",
       " 'unplannable',\n",
       " 'prayful',\n",
       " 'unmoored',\n",
       " 'scarey',\n",
       " 'fustrated',\n",
       " 'fruatated',\n",
       " 'discombobulated',\n",
       " 'aniexty',\n",
       " 'excitment',\n",
       " 'angustia',\n",
       " 'overwhemled',\n",
       " 'anexity',\n",
       " 'reiliance',\n",
       " 'selfconfidence',\n",
       " 'anixety',\n",
       " 'uncertanty',\n",
       " 'lonley',\n",
       " 'untethered',\n",
       " 'frustacion',\n",
       " 'figuroutable',\n",
       " 'disconnectedness',\n",
       " 'eustressed',\n",
       " 'adaptating',\n",
       " 'disappoinment',\n",
       " 'inadaquate',\n",
       " 'saddness',\n",
       " 'gratefulness']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "short_resp = []\n",
    "long_resp = []\n",
    "for i in y:\n",
    "    if len(i.split()) > 1:\n",
    "        long_resp = np.append(long_resp, i)  \n",
    "    else:\n",
    "        short_resp = np.append(short_resp, i)\n",
    "\n",
    "\n",
    "spell = SpellChecker()\n",
    "misspelled = spell.unknown(short_resp)\n",
    "list_misspelled = list(misspelled)\n",
    "\n",
    "len(list_misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_words = []\n",
    "for word in list_misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    corrected_words = np.append(corrected_words, spell.correction(word) )\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group = np.append(corrected_words, short_resp)\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_forms.word_forms import get_word_forms\n",
    "def all_word_forms(word_list):   \n",
    "    synonyms_cleaned = [syns for syns in word_list if str(syns) != 'nan']\n",
    "    word_derivations = []\n",
    "    for i in synonyms_cleaned:\n",
    "        x = get_word_forms(i)\n",
    "        noun = list(x['n'])\n",
    "        adj = list(x['a'])\n",
    "        verb = list(x['v'])\n",
    "        r_set = list(x['r'])\n",
    "        new = noun + adj +verb+r_set \n",
    "        word_derivations = np.append(word_derivations, new)\n",
    "    return word_derivations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
